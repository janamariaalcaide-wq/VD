# -*- coding: utf-8 -*-
"""VD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/163osb8WRzi8viOgPJxv5283PmBntEPv9
"""



import streamlit as st
import pandas as pd
import glob
import re
import os
import numpy as np
from sklearn.metrics import (
    precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score, log_loss
)
import altair as alt
import matplotlib.pyplot as plt


def cargar_archivos(patron, columna_nvariables=True, columna_nfolds=True, columna_fold=True):
    archivos = glob.glob(patron)
    dfs = []
    pattern_nv = re.compile(r'nV(\d+)')
    pattern_nf = re.compile(r'nF(\d+)')
    pattern_s = re.compile(r'_S\d+')  # para eliminar '_S0', '_S1', etc.
    pattern_seed = re.compile(r'Seed[_]?(\d+)')  # para extraer el número de Seed
    pattern_fold = re.compile(r'_Fold(\d+)')  # nuevo patrón para Fold

    for archivo in archivos:
        df = pd.read_csv(archivo)
        nombre_archivo = os.path.basename(archivo)

        # Añadir columna Nvariables
        if columna_nvariables:
            match_nv = pattern_nv.search(archivo)
            if match_nv:
                n_variables = int(match_nv.group(1))
            else:
                n_variables = None
            df['Nvariables'] = n_variables

        # Añadir columna nFolds
        if columna_nfolds:
            match_nf = pattern_nf.search(archivo)
            if match_nf:
                n_folds = int(match_nf.group(1))
            else:
                n_folds = None
            df['nFolds'] = n_folds

        # Añadir columna Fold (si se especifica y si en el nombre aparece)
        if columna_fold:
            match_fold = pattern_fold.search(nombre_archivo)
            if match_fold:
                fold_value = int(match_fold.group(1))
            else:
                fold_value = None
            df['Fold'] = fold_value

        # Si el archivo empieza por 'TestPredCV', eliminar '_S*_'
        if nombre_archivo.startswith('TestPredCV'):
            df.columns = [pattern_s.sub('', col) for col in df.columns]

        # Si en el nombre del archivo aparece 'Seed', extraer el valor
        match_seed = pattern_seed.search(nombre_archivo)
        if 'Seed' in nombre_archivo and match_seed:
            seed_value = int(match_seed.group(1))
            df['Seed'] = seed_value

        dfs.append(df)

    df_total = pd.concat(dfs, ignore_index=True)
    return df_total

patron_testpredcv = "DATOS/TestPredCV_ID_2C_NvsSD_nR0_nV*_nF*_Seed*.csv"
df_testpredcv_prev = cargar_archivos(patron_testpredcv, columna_nvariables=True,columna_nfolds=True)

patron_leaderboard = "DATOS/leaderboard_testset_ID_2C_NvsSD_nR0_nV*_nF*_Seed*_Fold*.csv"
df_leaderboard = cargar_archivos(patron_leaderboard, columna_nvariables=True,columna_nfolds=True)

patron_feature_importance = "DATOS/FeatureImportance_ID_2C_NvsSD_nR0_nV*_nF*.csv"
df_feature_importance = cargar_archivos(patron_feature_importance, columna_nvariables=True,columna_nfolds=True)

patron_metrics = "DATOS/Metrics_CV_ID_2C_NvsSD_nR0_nV*_nF*_Seed*.csv"
df_metrics = cargar_archivos(patron_metrics, columna_nvariables=True,columna_nfolds=True)

#Pivoto df_testpredcv que tiene los valores para modelos en columnas
def extraer_modelos(df):
    modelos = set()
    for col in df.columns:
        match_numfold = re.match(r'testNumFold_(\w+)', col)
        match_proba = re.match(r'testPredProba_(\w+)', col)
        if match_numfold:
            modelos.add(match_numfold.group(1))
        elif match_proba:
            modelos.add(match_proba.group(1))
    return sorted(modelos)

modelos = extraer_modelos(df_testpredcv_prev)
filas_transformadas = []
for _, fila in df_testpredcv_prev.iterrows():
    base_info = {
        'Nvariables': fila['Nvariables'],
        'nFolds': fila['nFolds'],
        'Seed': fila['Seed'],
        'etiq-id': fila['etiq-id'],
        'clasereal': fila['ED_2Clases']
    }
    for modelo in modelos:
        fila_modelo = base_info.copy()
        fila_modelo['model'] = modelo
        test_numfold_col = f'testNumFold_{modelo}'
        test_proba_col = f'testPredProba_{modelo}'
        fila_modelo['testNumFold'] = fila[test_numfold_col] if test_numfold_col in df_testpredcv_prev.columns else None
        fila_modelo['testPredProba'] = fila[test_proba_col] if test_proba_col in df_testpredcv_prev.columns else None
        filas_transformadas.append(fila_modelo)
df_testpredcv = pd.DataFrame(filas_transformadas)

#voy a ordenar las tablas para poner las claves primero
def reordenar_columnas(df):
    df.columns = [
        'Seed' if col.lower() == 'seed' else col
        for col in df.columns
    ]
    df.columns = [
        'model' if re.search(r'modelname', col, re.IGNORECASE) else col
        for col in df.columns
    ]
    df.columns = [
        'Model' if col.lower() == 'model' else col
        for col in df.columns
    ]
    columnas_prioridad = ['Model', 'Nvariables', 'nFolds', 'Seed', 'Fold']
    columnas_actuales = list(df.columns)
    columnas_prioridad_existentes = [col for col in columnas_prioridad if col in columnas_actuales]
    nuevas_columnas = columnas_prioridad_existentes + [col for col in columnas_actuales if col not in columnas_prioridad_existentes]
    return df[nuevas_columnas]

df_testpredcv = reordenar_columnas(df_testpredcv)
df_leaderboard = reordenar_columnas(df_leaderboard)
df_feature_importance = reordenar_columnas(df_feature_importance)
df_metrics = reordenar_columnas(df_metrics)

# Creo un diccionario para homogenerizar nombres de df_metrics y df_leader board
# Creo un diccionario para homogenerizar nombres de df_metrics y df_leader board
mapeo_metricas = {
    # Métricas de precisión
    'precision_macro': 'Precision',
    'Precision_macro': 'Precision_macro',
    'precision': 'Precision',
    'Precision_weighted': 'Precision_weighted',
    'average_precision': 'average_precision',
    'Precision_0': 'Precision_0',
    'Precision_1': 'Precision_1',
    # Métricas de recall
    'recall_macro': 'Recall_macro',
    'Recall_macro': 'Recall_macro',
    'recall': 'Recall',
    'Recall_weighted': 'Recall_Weighted',
    'Recall_0': 'Recall_0',
    'Recall_1': 'Recall_1',
    # Métricas de F1
    'f1': 'F1',
    'F1_macro': 'F1_macro',
    'f1_micro': 'F1_micro',
    'F1_weighted': 'F1_weighted',
    # Métricas de evaluación general
    'balanced_accuracy': 'Balanced_Accuracy',
    'Balanced_accuracy': 'Balanced_Accuracy',
    'roc_auc': 'ROC_AUC',
    'Roc_auc': 'ROC_AUC',
    'auc': 'ROC_AUC',
    'pr_auc': 'PR_AUC',
    'score_test': 'Score_Test',
    'score_val': 'Score_Validation',
    'log_loss': 'Log_Loss',
}

def renombrar_columnas(df, mapeo):
    columnas_actuales = df.columns
    nuevas_columnas = {}
    for col in columnas_actuales:
        col_lower = col.lower()
        if col in mapeo:
            nuevas_columnas[col] = mapeo[col]
        elif col_lower in [k.lower() for k in mapeo]:
            key = [k for k in mapeo if k.lower() == col_lower][0]
            nuevas_columnas[col] = mapeo[key]
        else:
            nuevas_columnas[col] = col
    df_renombrado = df.rename(columns=nuevas_columnas)
    return df_renombrado
df_metrics = renombrar_columnas(df_metrics, mapeo_metricas)
df_leaderboard = renombrar_columnas(df_leaderboard, mapeo_metricas)


#""" Presentación
#Voy a acometer objetivos en primer lugar:
#- Dadas varias particiones del conjunto de entrenamiento, ¿qué partición tiene un comportamiento medio, cuál tiene el peor comportamiento y cuál el mejor?
#- Dados varios modelos de ML que solucionan el problema. ¿Cuáles son los 5 modelos que tienen un comportamiento más robusto?¿cuáles son sus característicsa?
#- De todas las variables del dataset de entrada, cuáles son las más relevantes teniendo en cuenta los resultados de cada modelo.
#- De todas las configuraciones de parámetros probadas para una misma arquitectura, seleccionar el subconjunto de las más prometedoras.


# Supongo que ya tienes tu DataFrame df_metrics cargado
df = df_metrics

# --- Filtros en sidebar ---
st.sidebar.title("Filtros")
nvariables_options = sorted(df['Nvariables'].unique())
nfolds_options = sorted(df['nFolds'].unique())
seed_options = sorted(df['Seed'].unique())

nvariables_filter = st.sidebar.multiselect(
    "Número de variables del modelo",
    options=nvariables_options,
    default=nvariables_options
)

nfolds_filter = st.sidebar.multiselect(
    "Filtrar por NFolds",
    options=nfolds_options,
    default=nfolds_options
)

seed_filter = st.sidebar.multiselect(
    "Filtrar por Seed",
    options=seed_options,
    default=seed_options
)


# --- Selector para k (número de mejores modelos) ---
k = st.slider('Selecciona los k mejores modelos a mostrar', min_value=1, max_value=10, value=5)

# --- Filtrado ---
df_top = df[
    (df['Nvariables'].isin(nvariables_filter)) &
    (df['nFolds'].isin(nfolds_filter)) &
    (df['Seed'].isin(seed_filter))
]

# --- Agrupar por Seed y calcular ROC_AUC medio ---
roc_by_seed = df_top.groupby('Seed')['ROC_AUC'].mean().reset_index()

# Calcular ROC_AUC medio global
roc_mean = roc_by_seed['ROC_AUC'].mean()

# Ordenar por ROC_AUC y seleccionar los top k
roc_top_k = roc_by_seed.nlargest(k, 'ROC_AUC')

# --- Layout ---
st.markdown("## Visualización de métricas y modelos")

col1, col2 = st.columns([1, 2])  # ajusta los ratios

with col1:
    st.write("### Distribución ROC_AUC por Seed (Barra)")
    fig, ax = plt.subplots()
    # Barras por seed
    ax.bar(roc_by_seed['Seed'], roc_by_seed['ROC_AUC'])
    # Línea con ROC medio
    ax.axhline(roc_mean, color='red', linestyle='--', label=f'ROC medio: {roc_mean:.3f}')
    ax.set_xlabel('Seed')
    ax.set_ylabel('ROC_AUC')
    ax.set_title('ROC_AUC promedio por Seed')
    ax.legend()
    st.pyplot(fig)
    st.write("### Información adicional")
    min_seed = roc_by_seed.loc[roc_by_seed['ROC_AUC'].idxmin(), 'Seed']
    max_seed = roc_by_seed.loc[roc_by_seed['ROC_AUC'].idxmax(), 'Seed']
    closest_seed = roc_by_seed.loc[(abs(roc_by_seed['ROC_AUC'] - roc_mean)).idxmin(), 'Seed']
    mean_value = roc_by_seed['ROC_AUC'].mean()
    st.write(f"Seed con mínimo ROC_AUC: {min_seed}")
    st.write(f"Seed con máximo ROC_AUC: {max_seed}")
    st.write(f"Seed más cercano al promedio: {closest_seed}")
    st.write(f"Valor promedio de ROC_AUC: {mean_value:.3f}")

with col2:
    # Diagrama de burbujas solo para los k mejores modelos
    df_top_models = df[df['Model'].isin(roc_top_k['Seed'])]  # o ajusta si 'Model' es diferente
    # Nota: quizás quieres filtrar por alguna métrica específica o por otra columna
    chart = alt.Chart(
        df_top_models
    ).mark_circle().encode(
        x=alt.X('Precision_macro', title='Precisión', scale=alt.Scale(domain=[0.7, 0.9])),
        y=alt.Y('Recall_macro', title='Recall', scale=alt.Scale(domain=[0.7, 0.9])),
        size=alt.Size('ROC_AUC', title='ROC_AUC', scale=alt.Scale(range=[400, 1000])),
        color=alt.Color('Model', legend=alt.Legend(title="Model")),
        tooltip=['Model','ROC_AUC','Precision_macro','Recall_macro']
    ).properties(
        width=700,
        height=500,
        title=f'Modelos con ROC_AUC entre los {k} mejores'
    )
    st.altair_chart(chart, use_container_width=True)