# -*- coding: utf-8 -*-
"""VD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/163osb8WRzi8viOgPJxv5283PmBntEPv9
"""



import streamlit as st
import pandas as pd
import glob
import re
import os
import numpy as np
from sklearn.metrics import (
    precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score, log_loss
)
import altair as alt
import matplotlib.pyplot as plt


def cargar_archivos(patron, columna_nvariables=True, columna_nfolds=True, columna_fold=True):
    archivos = glob.glob(patron)
    dfs = []
    pattern_nv = re.compile(r'nV(\d+)')
    pattern_nf = re.compile(r'nF(\d+)')
    pattern_s = re.compile(r'_S\d+')  # para eliminar '_S0', '_S1', etc.
    pattern_seed = re.compile(r'Seed[_]?(\d+)')  # para extraer el número de Seed
    pattern_fold = re.compile(r'_Fold(\d+)')  # nuevo patrón para Fold

    for archivo in archivos:
        df = pd.read_csv(archivo)
        nombre_archivo = os.path.basename(archivo)

        # Añadir columna Nvariables
        if columna_nvariables:
            match_nv = pattern_nv.search(archivo)
            if match_nv:
                n_variables = int(match_nv.group(1))
            else:
                n_variables = None
            df['Nvariables'] = n_variables

        # Añadir columna nFolds
        if columna_nfolds:
            match_nf = pattern_nf.search(archivo)
            if match_nf:
                n_folds = int(match_nf.group(1))
            else:
                n_folds = None
            df['nFolds'] = n_folds

        # Añadir columna Fold (si se especifica y si en el nombre aparece)
        if columna_fold:
            match_fold = pattern_fold.search(nombre_archivo)
            if match_fold:
                fold_value = int(match_fold.group(1))
            else:
                fold_value = None
            df['Fold'] = fold_value

        # Si el archivo empieza por 'TestPredCV', eliminar '_S*_'
        if nombre_archivo.startswith('TestPredCV'):
            df.columns = [pattern_s.sub('', col) for col in df.columns]

        # Si en el nombre del archivo aparece 'Seed', extraer el valor
        match_seed = pattern_seed.search(nombre_archivo)
        if 'Seed' in nombre_archivo and match_seed:
            seed_value = int(match_seed.group(1))
            df['Seed'] = seed_value

        dfs.append(df)

    df_total = pd.concat(dfs, ignore_index=True)
    return df_total

patron_testpredcv = "DATOS/TestPredCV_ID_2C_NvsSD_nR0_nV*_nF*_Seed*.csv"
df_testpredcv_prev = cargar_archivos(patron_testpredcv, columna_nvariables=True,columna_nfolds=True)

patron_leaderboard = "DATOS/leaderboard_testset_ID_2C_NvsSD_nR0_nV*_nF*_Seed*_Fold*.csv"
df_leaderboard = cargar_archivos(patron_leaderboard, columna_nvariables=True,columna_nfolds=True)

patron_feature_importance = "DATOS/FeatureImportance_ID_2C_NvsSD_nR0_nV*_nF*.csv"
df_feature_importance = cargar_archivos(patron_feature_importance, columna_nvariables=True,columna_nfolds=True)

patron_metrics = "DATOS/Metrics_CV_ID_2C_NvsSD_nR0_nV*_nF*_Seed*.csv"
df_metrics = cargar_archivos(patron_metrics, columna_nvariables=True,columna_nfolds=True)

#Pivoto df_testpredcv que tiene los valores para modelos en columnas
def extraer_modelos(df):
    modelos = set()
    for col in df.columns:
        match_numfold = re.match(r'testNumFold_(\w+)', col)
        match_proba = re.match(r'testPredProba_(\w+)', col)
        if match_numfold:
            modelos.add(match_numfold.group(1))
        elif match_proba:
            modelos.add(match_proba.group(1))
    return sorted(modelos)

modelos = extraer_modelos(df_testpredcv_prev)
filas_transformadas = []
for _, fila in df_testpredcv_prev.iterrows():
    base_info = {
        'Nvariables': fila['Nvariables'],
        'nFolds': fila['nFolds'],
        'Seed': fila['Seed'],
        'etiq-id': fila['etiq-id'],
        'clasereal': fila['ED_2Clases']
    }
    for modelo in modelos:
        fila_modelo = base_info.copy()
        fila_modelo['model'] = modelo
        test_numfold_col = f'testNumFold_{modelo}'
        test_proba_col = f'testPredProba_{modelo}'
        fila_modelo['testNumFold'] = fila[test_numfold_col] if test_numfold_col in df_testpredcv_prev.columns else None
        fila_modelo['testPredProba'] = fila[test_proba_col] if test_proba_col in df_testpredcv_prev.columns else None
        filas_transformadas.append(fila_modelo)
df_testpredcv = pd.DataFrame(filas_transformadas)

#voy a ordenar las tablas para poner las claves primero
def reordenar_columnas(df):
    df.columns = [
        'Seed' if col.lower() == 'seed' else col
        for col in df.columns
    ]
    df.columns = [
        'model' if re.search(r'modelname', col, re.IGNORECASE) else col
        for col in df.columns
    ]
    df.columns = [
        'Model' if col.lower() == 'model' else col
        for col in df.columns
    ]
    columnas_prioridad = ['Model', 'Nvariables', 'nFolds', 'Seed', 'Fold']
    columnas_actuales = list(df.columns)
    columnas_prioridad_existentes = [col for col in columnas_prioridad if col in columnas_actuales]
    nuevas_columnas = columnas_prioridad_existentes + [col for col in columnas_actuales if col not in columnas_prioridad_existentes]
    return df[nuevas_columnas]

df_testpredcv = reordenar_columnas(df_testpredcv)
df_leaderboard = reordenar_columnas(df_leaderboard)
df_feature_importance = reordenar_columnas(df_feature_importance)
df_metrics = reordenar_columnas(df_metrics)

# Creo un diccionario para homogenerizar nombres de df_metrics y df_leader board
# Creo un diccionario para homogenerizar nombres de df_metrics y df_leader board
mapeo_metricas = {
    # Métricas de precisión
    'precision_macro': 'Precision',
    'Precision_macro': 'Precision_macro',
    'precision': 'Precision',
    'Precision_weighted': 'Precision_weighted',
    'average_precision': 'average_precision',
    'Precision_0': 'Precision_0',
    'Precision_1': 'Precision_1',
    # Métricas de recall
    'recall_macro': 'Recall_macro',
    'Recall_macro': 'Recall_macro',
    'recall': 'Recall',
    'Recall_weighted': 'Recall_Weighted',
    'Recall_0': 'Recall_0',
    'Recall_1': 'Recall_1',
    # Métricas de F1
    'f1': 'F1',
    'F1_macro': 'F1_macro',
    'f1_micro': 'F1_micro',
    'F1_weighted': 'F1_weighted',
    # Métricas de evaluación general
    'balanced_accuracy': 'Balanced_Accuracy',
    'Balanced_accuracy': 'Balanced_Accuracy',
    'roc_auc': 'ROC_AUC',
    'Roc_auc': 'ROC_AUC',
    'auc': 'ROC_AUC',
    'pr_auc': 'PR_AUC',
    'score_test': 'Score_Test',
    'score_val': 'Score_Validation',
    'log_loss': 'Log_Loss',
}

def renombrar_columnas(df, mapeo):
    columnas_actuales = df.columns
    nuevas_columnas = {}
    for col in columnas_actuales:
        col_lower = col.lower()
        if col in mapeo:
            nuevas_columnas[col] = mapeo[col]
        elif col_lower in [k.lower() for k in mapeo]:
            key = [k for k in mapeo if k.lower() == col_lower][0]
            nuevas_columnas[col] = mapeo[key]
        else:
            nuevas_columnas[col] = col
    df_renombrado = df.rename(columns=nuevas_columnas)
    return df_renombrado
df_metrics = renombrar_columnas(df_metrics, mapeo_metricas)
df_leaderboard = renombrar_columnas(df_leaderboard, mapeo_metricas)


#""" Presentación
#Voy a acometer objetivos en primer lugar:
#- Dadas varias particiones del conjunto de entrenamiento, ¿qué partición tiene un comportamiento medio, cuál tiene el peor comportamiento y cuál el mejor?
#- Dados varios modelos de ML que solucionan el problema. ¿Cuáles son los 5 modelos que tienen un comportamiento más robusto?¿cuáles son sus característicsa?
#- De todas las variables del dataset de entrada, cuáles son las más relevantes teniendo en cuenta los resultados de cada modelo.
#- De todas las configuraciones de parámetros probadas para una misma arquitectura, seleccionar el subconjunto de las más prometedoras.

st.markdown(
    """
    <style>
    .streamlit-expander > div, .css-1l02zno { 
        padding: 0 !important; 
        margin: 0 !important;
    }
    </style>
    """, unsafe_allow_html=True
)
# Supongo que ya tienes tu DataFrame df_metrics cargado
df = df_metrics

# --- Filtros en sidebar ---
st.sidebar.title("Filtros")
nvariables_options = sorted(df['Nvariables'].unique())
nfolds_options = sorted(df['nFolds'].unique())
seed_options = sorted(df['Seed'].unique())

nvariables_filter = st.sidebar.multiselect(
    "Número de variables del modelo",
    options=nvariables_options,
    default=nvariables_options
)

nfolds_filter = st.sidebar.multiselect(
    "Filtrar por NFolds",
    options=nfolds_options,
    default=nfolds_options
)

seed_filter = st.sidebar.multiselect(
    "Filtrar por Seed",
    options=seed_options,
    default=seed_options
)

# --- Filtrado ---
df_top = df[
    (df['Nvariables'].isin(nvariables_filter)) &
    (df['nFolds'].isin(nfolds_filter)) &
    (df['Seed'].isin(seed_filter))
]

stats = df_top.groupby('Seed')['ROC_AUC'].agg(['mean', 'min', 'max']).reset_index()

# Preparamos los datos para las líneas
lines_data = pd.DataFrame({
    'Seed': list(stats['Seed']) * 3,
    'value': list(stats['mean']) + list(stats['min']) + list(stats['max']),
    'label': ['mean']]*len(stats) + ['min']*len(stats) + ['max']*len(stats)
})

# Gráfico de barras: media de ROC_AUC por seed
bars = alt.Chart(roc_by_seed).mark_bar().encode(
    x=alt.X('Seed:N', title='Seed', axis=alt.Axis(labelAngle=45)),
    y=alt.Y('ROC_AUC:Q', title='ROC_AUC medio', scale=alt.Scale(domain=[0.85, 0.94])),
    color=alt.Color('Seed:N', legend=None),
    tooltip=['Seed', 'ROC_AUC']
).properties(
    width=600,
    height=400,
    title='ROC_AUC medio por Seed con líneas de referencia'
)

# Líneas horizontales para media, mínimo y máximo
lines = alt.Chart(lines_data).mark_rule().encode(
    x=alt.X('Seed:N', axis=None),
    y=alt.Y('value:Q', scale=alt.Scale(domain=[0.85, 0.94])),
    color=alt.Color('label:N', legend=None),
    strokeDash=alt.StrokeDash('label:N', legend=None)
)

# Añadimos etiquetas a las líneas (opcional)
labels = alt.Chart(lines_data).mark_text(
    align='left',
    dx=5,
    dy=-5
).encode(
    x=alt.X('Seed:N', axis=None),
    y='value:Q',
    text='label:N'
)

# Combinamos todo
chart = alt.layer(bars, lines, labels).resolve_scale(
    y='shared'
)

# Aquí tu diagrama de burbujas
chart = alt.Chart(
    df_top
).mark_circle().encode(
    x=alt.X('Precision_macro', title='Precisión', scale=alt.Scale(domain=[0.7, 0.9])),
    y=alt.Y('Recall_macro', title='Recall', scale=alt.Scale(domain=[0.7, 0.9])),
    size=alt.Size('ROC_AUC', title='ROC_AUC', scale=alt.Scale(range=[400, 1000])),
    color=alt.Color('Model', legend=alt.Legend(title="Model")),
    tooltip=['Model','ROC_AUC','Precision_macro','Recall_macro']
).properties(
    width=400,
    height=600,
    title='Modelos con métricas medias: Precisión vs Recall, tamaño por ROC_AUC'
)
st.altair_chart(chart, use_container_width=True)

