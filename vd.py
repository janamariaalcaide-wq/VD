# -*- coding: utf-8 -*-
"""VD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/163osb8WRzi8viOgPJxv5283PmBntEPv9
"""



import streamlit as st
import pandas as pd
import glob
import re
import os
import numpy as np
from sklearn.metrics import (
    precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score, log_loss
)
import altair as alt


def cargar_archivos(patron, columna_nvariables=True, columna_nfolds=True, columna_fold=True):
    archivos = glob.glob(patron)
    dfs = []
    pattern_nv = re.compile(r'nV(\d+)')
    pattern_nf = re.compile(r'nF(\d+)')
    pattern_s = re.compile(r'_S\d+')  # para eliminar '_S0', '_S1', etc.
    pattern_seed = re.compile(r'Seed[_]?(\d+)')  # para extraer el número de Seed
    pattern_fold = re.compile(r'_Fold(\d+)')  # nuevo patrón para Fold

    for archivo in archivos:
        df = pd.read_csv(archivo)
        nombre_archivo = os.path.basename(archivo)

        # Añadir columna Nvariables
        if columna_nvariables:
            match_nv = pattern_nv.search(archivo)
            if match_nv:
                n_variables = int(match_nv.group(1))
            else:
                n_variables = None
            df['Nvariables'] = n_variables

        # Añadir columna nFolds
        if columna_nfolds:
            match_nf = pattern_nf.search(archivo)
            if match_nf:
                n_folds = int(match_nf.group(1))
            else:
                n_folds = None
            df['nFolds'] = n_folds

        # Añadir columna Fold (si se especifica y si en el nombre aparece)
        if columna_fold:
            match_fold = pattern_fold.search(nombre_archivo)
            if match_fold:
                fold_value = int(match_fold.group(1))
            else:
                fold_value = None
            df['Fold'] = fold_value

        # Si el archivo empieza por 'TestPredCV', eliminar '_S*_'
        if nombre_archivo.startswith('TestPredCV'):
            df.columns = [pattern_s.sub('', col) for col in df.columns]

        # Si en el nombre del archivo aparece 'Seed', extraer el valor
        match_seed = pattern_seed.search(nombre_archivo)
        if 'Seed' in nombre_archivo and match_seed:
            seed_value = int(match_seed.group(1))
            df['Seed'] = seed_value

        dfs.append(df)

    df_total = pd.concat(dfs, ignore_index=True)
    return df_total

patron_testpredcv = "DATOS/TestPredCV_ID_2C_NvsSD_nR0_nV*_nF*_Seed*.csv"
df_testpredcv_prev = cargar_archivos(patron_testpredcv, columna_nvariables=True,columna_nfolds=True)

patron_leaderboard = "DATOS/leaderboard_testset_ID_2C_NvsSD_nR0_nV*_nF*_Seed*_Fold*.csv"
df_leaderboard = cargar_archivos(patron_leaderboard, columna_nvariables=True,columna_nfolds=True)

patron_feature_importance = "DATOS/FeatureImportance_ID_2C_NvsSD_nR0_nV*_nF*.csv"
df_feature_importance = cargar_archivos(patron_feature_importance, columna_nvariables=True,columna_nfolds=True)

patron_metrics = "DATOS/Metrics_CV_ID_2C_NvsSD_nR0_nV*_nF*_Seed*.csv"
df_metrics = cargar_archivos(patron_metrics, columna_nvariables=True,columna_nfolds=True)

#Pivoto df_testpredcv que tiene los valores para modelos en columnas
def extraer_modelos(df):
    modelos = set()
    for col in df.columns:
        match_numfold = re.match(r'testNumFold_(\w+)', col)
        match_proba = re.match(r'testPredProba_(\w+)', col)
        if match_numfold:
            modelos.add(match_numfold.group(1))
        elif match_proba:
            modelos.add(match_proba.group(1))
    return sorted(modelos)

modelos = extraer_modelos(df_testpredcv_prev)
filas_transformadas = []
for _, fila in df_testpredcv_prev.iterrows():
    base_info = {
        'Nvariables': fila['Nvariables'],
        'nFolds': fila['nFolds'],
        'Seed': fila['Seed'],
        'etiq-id': fila['etiq-id'],
        'clasereal': fila['ED_2Clases']
    }
    for modelo in modelos:
        fila_modelo = base_info.copy()
        fila_modelo['model'] = modelo
        test_numfold_col = f'testNumFold_{modelo}'
        test_proba_col = f'testPredProba_{modelo}'
        fila_modelo['testNumFold'] = fila[test_numfold_col] if test_numfold_col in df_testpredcv_prev.columns else None
        fila_modelo['testPredProba'] = fila[test_proba_col] if test_proba_col in df_testpredcv_prev.columns else None
        filas_transformadas.append(fila_modelo)
df_testpredcv = pd.DataFrame(filas_transformadas)

#voy a ordenar las tablas para poner las claves primero
def reordenar_columnas(df):
    df.columns = [
        'Seed' if col.lower() == 'seed' else col
        for col in df.columns
    ]
    df.columns = [
        'model' if re.search(r'modelname', col, re.IGNORECASE) else col
        for col in df.columns
    ]
    df.columns = [
        'Model' if col.lower() == 'model' else col
        for col in df.columns
    ]
    columnas_prioridad = ['Model', 'Nvariables', 'nFolds', 'Seed', 'Fold']
    columnas_actuales = list(df.columns)
    columnas_prioridad_existentes = [col for col in columnas_prioridad if col in columnas_actuales]
    nuevas_columnas = columnas_prioridad_existentes + [col for col in columnas_actuales if col not in columnas_prioridad_existentes]
    return df[nuevas_columnas]

df_testpredcv = reordenar_columnas(df_testpredcv)
df_leaderboard = reordenar_columnas(df_leaderboard)
df_feature_importance = reordenar_columnas(df_feature_importance)
df_metrics = reordenar_columnas(df_metrics)

# Creo un diccionario para homogenerizar nombres de df_metrics y df_leader board
# Creo un diccionario para homogenerizar nombres de df_metrics y df_leader board
mapeo_metricas = {
    # Métricas de precisión
    'precision_macro': 'Precision',
    'Precision_macro': 'Precision_macro',
    'precision': 'Precision',
    'Precision_weighted': 'Precision_weighted',
    'average_precision': 'average_precision',
    'Precision_0': 'Precision_0',
    'Precision_1': 'Precision_1',
    # Métricas de recall
    'recall_macro': 'Recall_macro',
    'Recall_macro': 'Recall_macro',
    'recall': 'Recall',
    'Recall_weighted': 'Recall_Weighted',
    'Recall_0': 'Recall_0',
    'Recall_1': 'Recall_1',
    # Métricas de F1
    'f1': 'F1',
    'F1_macro': 'F1_macro',
    'f1_micro': 'F1_micro',
    'F1_weighted': 'F1_weighted',
    # Métricas de evaluación general
    'balanced_accuracy': 'Balanced_Accuracy',
    'Balanced_accuracy': 'Balanced_Accuracy',
    'roc_auc': 'ROC_AUC',
    'Roc_auc': 'ROC_AUC',
    'auc': 'ROC_AUC',
    'pr_auc': 'PR_AUC',
    'score_test': 'Score_Test',
    'score_val': 'Score_Validation',
    'log_loss': 'Log_Loss',
}

def renombrar_columnas(df, mapeo):
    columnas_actuales = df.columns
    nuevas_columnas = {}
    for col in columnas_actuales:
        col_lower = col.lower()
        if col in mapeo:
            nuevas_columnas[col] = mapeo[col]
        elif col_lower in [k.lower() for k in mapeo]:
            key = [k for k in mapeo if k.lower() == col_lower][0]
            nuevas_columnas[col] = mapeo[key]
        else:
            nuevas_columnas[col] = col
    df_renombrado = df.rename(columns=nuevas_columnas)
    return df_renombrado
df_metrics = renombrar_columnas(df_metrics, mapeo_metricas)
df_leaderboard = renombrar_columnas(df_leaderboard, mapeo_metricas)


#""" Presentación
#Voy a acometer objetivos en primer lugar:
#- Dadas varias particiones del conjunto de entrenamiento, ¿qué partición tiene un comportamiento medio, cuál tiene el peor comportamiento y cuál el mejor?
#- Dados varios modelos de ML que solucionan el problema. ¿Cuáles son los 5 modelos que tienen un comportamiento más robusto?¿cuáles son sus característicsa?
#- De todas las variables del dataset de entrada, cuáles son las más relevantes teniendo en cuenta los resultados de cada modelo.
#- De todas las configuraciones de parámetros probadas para una misma arquitectura, seleccionar el subconjunto de las más prometedoras.


df = df_metrics
top_models = (
    df.groupby('Model')['ROC_AUC']
    .mean()
    .reset_index()
    .sort_values(by='ROC_AUC', ascending=False)
    .head(5)
)

# Filtrar los datos para solo esos modelos
df_top = df[df['Model'].isin(top_models['Model'])]

st.sidebar.title("Filtros")

nvariables_options = sorted(df['Nvariables'].unique())
nfolds_options = sorted(df['nFolds'].unique())
seed_options = sorted(df['Seed'].unique())

# Crear filtros con multiselect
# Filtro de Nvariables como selectbox
nvariables_filter = st.sidebar.selectbox(
    "Número de variables del modelo",
    options=nvariables_options,
    index=0  # Puedes poner el índice por defecto
)

# Otros filtros como multiselect, con un estilo más bonito (puedes usar un tema si quieres)
nfolds_filter = st.sidebar.multiselect(
    "Filtrar por NFolds",
    options=nfolds_options,
    default=nfolds_options
)

seed_filter = st.sidebar.multiselect(
    "Filtrar por Seed",
    options=seed_options,
    default=seed_options
)

# --- Agrupar por modelo y calcular medias ---
grouped_df = filtered_df.groupby('Model').agg({
    'Precision_macro': 'mean',
    'Recall_macro': 'mean',
    'ROC_AUC': 'mean',
    'Nvariables': 'mean',
    'nFolds': 'mean',
    'Seed': 'mean'
}).reset_index()

# --- Crear la visualización ---
chart = alt.Chart(grouped_df).mark_circle().encode(
    x=alt.X('Precision_macro', title='Precisión', scale=alt.Scale(domain=[0.7, 1])),
    y=alt.Y('Recall_macro', title='Recall', scale=alt.Scale(domain=[0.7, 1])),
    size=alt.Size('ROC_AUC', title='ROC_AUC', scale=alt.Scale(range=[50, 300]), size_max=100),
    color=alt.Color('Model', legend=alt.Legend(title="Model")),
    tooltip=[
        'Model'
    ]
).properties(
    width=700,
    height=500,
    title='Modelos con métricas medias: Precisión vs Recall, tamaño por ROC_AUC'
)

st.altair_chart(chart, use_container_width=True)